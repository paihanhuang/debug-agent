### Goal
Improve report quality (especially **Metric Precision**) by ensuring that if the user prompt contains metrics like **DDR5460**, **DDR6370**, and **CPU frequencies**, they are **naturally blended** into the final report.

We will do this via a **second LLM “editor” pass** (default ON) that rewrites the draft report to include required facts without changing meaning or inventing numbers.

---

### Key decision (per your request)
- The **2nd LLM editor pass is the default behavior**.
- A feature flag exists only to **disable** it when needed:
  - `ENABLE_REPORT_METRIC_REWRITE`
  - Default = enabled
  - Disable with `ENABLE_REPORT_METRIC_REWRITE=0` (or `false`, `no`)

---

### Source of truth for “required facts”
- Use `MetricParser` output already present in retrieval context:
  - `debug-engine/src/graphrag/metric_parser.py` → `ExtractedMetrics`
  - Available fields include:
    - `ddr5460_percent`, `ddr6370_percent`, `ddr_total_percent`
    - `cpu_big_mhz`, `cpu_mid_mhz`, `cpu_small_mhz`
    - `sw_req_flags`
    - `vcore_percent`, `mmdvfs_opp`, etc.

The editor is required to use **only** these facts (and the existing draft text). It must not invent new metrics.

---

### Revised report generation flow
1. Retrieve context (`Retriever.retrieve`)
2. Build initial prompt (`DebugAgent._build_prompt`)
3. **LLM draft** report generation (existing)
4. Existing post-processing (keep):
   - `_ensure_traversal_nodes(...)` (LLM-based editor for node inclusion)
5. **NEW: LLM metric editor pass (default ON)**
   - `_rewrite_report_to_include_required_metrics(draft, context.metrics, required_tokens)`
6. Parse final report into sections (existing `_parse_response`)

---

### Editor pass details

#### Trigger conditions (when we call the editor LLM)
Call the editor if:
- feature flag enabled (default), AND
- at least one of these is present in `context.metrics`:
  - DDR5460%, DDR6370%, any CPU MHz values

We may **skip** the editor pass if the draft already contains all required mentions:
- If `ddr5460_percent` present → draft contains `DDR5460`
- If `ddr6370_percent` present → draft contains `DDR6370`
- If any cpu_*_mhz present → draft contains `MHz` (and ideally “CPU”)

Even with default-on, skipping when already satisfied reduces cost without changing behavior.

#### Inputs to the editor LLM
- The full draft report text (as generated by the first LLM call + traversal-node inclusion pass)
- A structured “Required Facts” list derived from `ExtractedMetrics`, e.g.:
  - `DDR5460: 3.54%`
  - `DDR6370: 26.13%`
  - `CPU freqs observed: big=2700MHz, mid=2400MHz, small=2100MHz`

#### Output requirements (hard rules)
Editor must:
- keep the same overall section structure (`## Root Cause`, `## Causal Chain`, `## Diagnosis`, `## Historical Fixes`)
- **blend** required facts naturally into existing sentences
- **not** add a new “Metric Echo” section
- **not** change any numeric values already present in the draft
- **not** invent any new numbers or facts beyond the required list
- return only the revised report text

#### Feature flag semantics
- `ENABLE_REPORT_METRIC_REWRITE` defaults to enabled if unset
- disable if value in `{0,false,no,off}` (case-insensitive)

---

### Implementation plan (V-model)

#### Tests first (debug-engine)
Add unit tests under `debug-engine/src/tests/` (mocking the LLM client):
- **T1: Editor called when required facts missing**
  - Draft lacks DDR5460/DDR6370/CPU freqs; metrics present → editor invoked once
- **T2: Editor skipped when already present**
  - Draft already mentions DDR5460/DDR6370/MHz → editor not invoked
- **T3: Feature flag disables editor**
  - `ENABLE_REPORT_METRIC_REWRITE=0` → editor not invoked
- **T4: Editor failure fallback**
  - Editor call raises → return draft unchanged
- **T5: Prompt contract**
  - Verify the editor prompt includes “do not change numeric values” and lists required facts explicitly

#### Implementation (debug-engine)
Modify `debug-engine/src/graphrag/agent.py`:
- Add an editor prompt template (system prompt) and helper method:
  - `_rewrite_report_to_include_required_metrics(draft: str, metrics: ExtractedMetrics) -> str`
- Add a “feature-flag check” helper
- Make the editor call via the same OpenAI client with low temperature
- (Testability) allow injecting a fake LLM client into `DebugAgent` for unit tests (optional param)

#### Verification
Run:
`PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 .venv/bin/python -m pytest -q debug-engine/src/tests`

